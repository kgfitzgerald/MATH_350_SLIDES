<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Teaching Demo: Intro to Logistic Regression</title>
    <meta charset="utf-8" />
    <meta name="author" content="Dr.Â Katie Fitzgerald" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <link href="libs/remark-css/default-fonts.css" rel="stylesheet" />
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <link href="libs/font-awesome/css/all.min.css" rel="stylesheet" />
    <link href="libs/font-awesome/css/v4-shims.min.css" rel="stylesheet" />
    <link href="libs/panelset/panelset.css" rel="stylesheet" />
    <script src="libs/panelset/panelset.js"></script>
    <link rel="stylesheet" href="boxes.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">





layout: true
  


---







class: middle, center

# Teaching Demo: Intro to Logistic Regression

---

# Context

+ Lecture I've given in APU's *Statistical Models* course, which has the equivalent of MATH 062 as a pre-req

--

+ Students already familiar with:
    + Distributions, expected value, etc.
    + basic linear regression / OLS
    + R/RStudio + Quarto documents + R projects

--

+ Students provided with:
    + Link to web-based lecture slides [https://kgfitzgerald.github.io/MATH_350_SLIDES/Ch7-M350-slides.html](https://kgfitzgerald.github.io/MATH_350_SLIDES/Ch7-M350-slides.html)
    + Link to course Github repo, with .qmd templates for in-class activities and assignments [https://github.com/kgfitzgerald/APU_MATH_350_templates/](https://github.com/kgfitzgerald/APU_MATH_350_templates/)
    
--

+ Material adapted from *Practicing Statistics: Guided Investigations for the Second Course* (Kuyper &amp; Skylar)

---

class: middle, center

# "The best thing about being a statistician is that you get to play in everyone's backyard" 

- John Tukey

---

# AE-CH7

+ Navigate to course Github page: [https://github.com/kgfitzgerald/APU_MATH_350_templates/](https://github.com/kgfitzgerald/APU_MATH_350_templates/)
+ Download AE_CH7.qmd and place in MATH_062 project folder
+ Render your .qmd

---

# Space Shuttle Investigation

.pull-left[

- January 28, 1986, NASA launched 25th shuttle flight from Kennedy Space Center in Florida. 
]

.pull-right[
&lt;img src="./images/fig7-1.png" width="60%" style="display: block; margin: auto;" /&gt;
]

---

# Space Shuttle Investigation

.pull-left[

- January 28, 1986, NASA launched 25th shuttle flight from Kennedy Space Center in Florida.

- 73 seconds into flight, external fuel tank collapsed and spilled liquid oxygen and hydrogen. Ignited and killed all 7 crew members on board. 
]

.pull-right[
&lt;img src="./images/fig7-1.png" width="60%" style="display: block; margin: auto;" /&gt;
]

---

# Space Shuttle Investigation

.pull-left[

- January 28, 1986, NASA launched 25th shuttle flight from Kennedy Space Center in Florida. 

- 73 seconds into flight, external fuel tank collapsed and spilled liquid oxygen and hydrogen. Ignited and killed all 7 crew members on board. 

- O-ring seal in the right solid rocket booster failed to isolate the fuel supply. 
]

.pull-right[
&lt;img src="./images/fig7-1.png" width="60%" style="display: block; margin: auto;" /&gt;
]

---

# Space Shuttle Investigation

.pull-left[

- January 28, 1986, NASA launched 25th shuttle flight from Kennedy Space Center in Florida. 

- 73 seconds into flight, external fuel tank collapsed and spilled liquid oxygen and hydrogen. Ignited and killed all 7 crew members on board. 

- O-ring seal in the right solid rocket booster failed to isolate the fuel supply. 

- Tragedy: engineers knew that cold temperatures caused O-rings to become brittle and fail to seal properly. Expected temperature for January 28, 1986 was 31 degrees Fahrenheit. 

]

.pull-right[
&lt;img src="./images/fig7-1.png" width="60%" style="display: block; margin: auto;" /&gt;
]

---

# Space Shuttle Investigation

.pull-left[

- January 28, 1986, NASA launched 25th shuttle flight from Kennedy Space Center in Florida. 

- 73 seconds into flight, external fuel tank collapsed and spilled liquid oxygen and hydrogen. Ignited and killed all 7 crew members on board. 

- O-ring seal in the right solid rocket booster failed to isolate the fuel supply. 

- Tragedy: engineers knew that cold temperatures caused O-rings to become brittle and fail to seal properly. Expected temperature for January 28, 1986 was 31 degrees Fahrenheit.

- They recommended against launch, but were overruled. A science communication / knowledge mobilization disaster!! ðŸ˜±ðŸ˜°
]

.pull-right[
&lt;img src="./images/fig7-1.png" width="60%" style="display: block; margin: auto;" /&gt;
]

---


# Research question &amp; data

.pull-left[
*What's the relationship between temperature and the likelihood of an O-ring failure?*

24 prior flights deemed successful by NASA because even though some O-ring damage had occurred, none of it was severe enough to allow gas to escape. 

In `shuttle` data (Table 7.1), launch considered successful if NO O-ring damage occurred.

]

.pull-right[
&lt;img src="./images/Table7-1.png" width="60%" style="display: block; margin: auto;" /&gt;
]

---

# `shuttle` data, AE #1-2


```
## Rows: 23
## Columns: 4
## $ flight_number &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13â€¦
## $ date          &lt;chr&gt; "4/12/1981", "11/12/1981", "3/22/1982", "â€¦
## $ temperature   &lt;dbl&gt; 66, 70, 69, 68, 67, 72, 73, 70, 57, 63, 7â€¦
## $ success       &lt;dbl&gt; 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0,â€¦
```

+ Question 1: explanatory and response variables?

+ Question 2: Imagine you're an engineer working for Thiokol Corporation prior to January 1986. Create a few graphs of the data in Table 7.1

--

Can we fit a linear model to this data?

---

# Linear vs. Logistic regression

+ Linear = continuous response variable
+ Logistic = dichotomous (binary) response variable

Examples:

+ whether disease is present or absent
+ whether or not a person is a good credit risk for a loan
+ whether or not a high schooler will graduate in 4 years
+ whether or not an individual is involved in substance abuse
+ Others?? 

--

Logistic regression is a classification method. It's the baseline algorithm for classification tasks in machine learning.

---

# Linear regression review

"Ordinary least squares regression": 

`$$y_i = \beta_0 + \beta_1x_i + \epsilon_i, \ \ \ i = 1,\dots n$$`

`$$E(Y_i | x_i) = \beta_0 + \beta_1x_i, \ \ \ i = 1, \dots n$$`

`$$\epsilon_i \overset{\text{iid}}{\sim} N(0, \sigma^2)$$`

&lt;img src="images/reg_curves.png" alt="regression curves" width="20%" /&gt;

--

## AE-CH7 #3 

+ Create scatterplot with a least squares regression line for the space shuttle data. 
+ Calculate the predicted response `\(\hat{y}_i = b_0 + b_1x_i\)` when temperature = 60 and when temperature = 85 degrees Fahrenheit.
+ What's wrong?

---

# Probability of success

When response is binary, instead of modeling Y as a function of X directly, we instead model the *probability of success* given X. 

That is, let $$
`\begin{aligned}
\pi_i &amp;= P(Y_i = 1 | x_i) = \text{Probability that a launch has no O-ring damage at temperature } x_i \\
&amp;= E(Y_i | x_i)
\end{aligned}`
$$

--

As our predictions for `\(x_i = 60\)` and `\(x_i = 85\)` demonstrated, if we simply use a linear model `\(\pi_i = E(Y_i|x_i) = \beta_0 + \beta_1x_i\)` to model the probability of success, we end up with invalid values for `\(\pi_i\)`. 

---

# Logistic regression


.pull-left[
Need a function that will restrict output to be between 0 and 1 (to behave like probabilities). 

]

.pull-right[
&lt;img src="./images/fig7-3.png" width="60%" style="display: block; margin: auto;" /&gt;
]

---

# Logistic regression


.pull-left[
Need a function that will restrict output to be between 0 and 1 (to behave like probabilities). 

`$$ln\left(\frac{\pi_i}{1 - \pi_i}\right) = \beta_0 + \beta_1x_i$$`

]

.pull-right[
&lt;img src="./images/fig7-3.png" width="60%" style="display: block; margin: auto;" /&gt;
]

---

# Logistic regression


.pull-left[
Need a function that will restrict output to be between 0 and 1 (to behave like probabilities). 

`$$ln\left(\frac{\pi_i}{1 - \pi_i}\right) = \beta_0 + \beta_1x_i$$`

+ ln is natural log

]

.pull-right[
&lt;img src="./images/fig7-3.png" width="60%" style="display: block; margin: auto;" /&gt;
]

---

# Logistic regression


.pull-left[
Need a function that will restrict output to be between 0 and 1 (to behave like probabilities). 

`$$ln\left(\frac{\pi_i}{1 - \pi_i}\right) = \beta_0 + \beta_1x_i$$`

+ ln is natural log
+ `\(\beta_0, \beta_1\)` are regression parameters

]

.pull-right[
&lt;img src="./images/fig7-3.png" width="60%" style="display: block; margin: auto;" /&gt;
]

---

# Logistic regression


.pull-left[
Need a function that will restrict output to be between 0 and 1 (to behave like probabilities). 

`$$ln\left(\frac{\pi_i}{1 - \pi_i}\right) = \beta_0 + \beta_1x_i$$`

+ ln is natural log
+ `\(\beta_0, \beta_1\)` are regression parameters
+ `\(\pi_i\)` is probability of a successful launch for a given temperature `\(x_i\)`


]

.pull-right[
&lt;img src="./images/fig7-3.png" width="60%" style="display: block; margin: auto;" /&gt;
]

---

# Logistic regression


.pull-left[
Need a function that will restrict output to be between 0 and 1 (to behave like probabilities). 

`$$ln\left(\frac{\pi_i}{1 - \pi_i}\right) = \beta_0 + \beta_1x_i$$`

+ ln is natural log
+ `\(\beta_0, \beta_1\)` are regression parameters
+ `\(\pi_i\)` is probability of a successful launch for a given temperature `\(x_i\)`

The ratio `\(\pi/(1 - \pi)\)` is called the **odds**, so `\(ln[\pi/(1 - \pi)]\)` is called the **log-odds**, or **logistic** or **logit** transformation of `\(\pi\)`

]

.pull-right[
&lt;img src="./images/fig7-3.png" width="60%" style="display: block; margin: auto;" /&gt;
]

---

# Logistic regression


.pull-left[
Need a function that will restrict output to be between 0 and 1 (to behave like probabilities). 

`$$ln\left(\frac{\pi_i}{1 - \pi_i}\right) = \beta_0 + \beta_1x_i$$`

+ ln is natural log
+ `\(\beta_0, \beta_1\)` are regression parameters
+ `\(\pi_i\)` is probability of a successful launch for a given temperature `\(x_i\)`

The ratio `\(\pi/(1 - \pi)\)` is called the **odds**, so `\(ln[\pi/(1 - \pi)]\)` is called the **log-odds**, or **logistic** or **logit** transformation of `\(\pi\)`

***NOTE: in statistics, when we say log, we always mean natural log.***

]

.pull-right[
&lt;img src="./images/fig7-3.png" width="60%" style="display: block; margin: auto;" /&gt;
]

---

# Logistic regression


.pull-left[
Need a function that will restrict output to be between 0 and 1 (to behave like probabilities). 

`$$ln\left(\frac{\pi_i}{1 - \pi_i}\right) = \beta_0 + \beta_1x_i$$`

+ ln is natural log
+ `\(\beta_0, \beta_1\)` are regression parameters
+ `\(\pi_i\)` is probability of a successful launch for a given temperature `\(x_i\)`

The ratio `\(\pi/(1 - \pi)\)` is called the **odds**, so `\(ln[\pi/(1 - \pi)]\)` is called the **log-odds**, or **logistic** or **logit** transformation of `\(\pi\)`

***NOTE: in statistics, when we say log, we always mean natural log.***

Solve for `\(\pi_i\)`
]

.pull-right[
&lt;img src="./images/fig7-3.png" width="60%" style="display: block; margin: auto;" /&gt;
]

---

# Logistic regression model

.pull-left[
`\(\pi_i = \frac{e^{\beta_0 + \beta_1x_i}}{1 + e^{\beta_0 + \beta_1x_i}}\)`

[Convince ourselves we fixed the 0-1 problem](https://www.desmos.com/calculator/l6jvacfgdh)

### Model assumptions

`\(Y_i \sim Bernoulli(\pi_i)\)`, for a given `\(x_i\)` 

`\(Y_i = \pi_i + \epsilon_i\)`

+ Each `\(Y_i\)` is independent
+ `\(Y_i\)` has only two possible outcomes, 0 and 1
+ `\(P(Y_i = 1 |x_i) = \pi_i\)`
+ `\(P(Y_i = 0 | x_i) = 1 - \pi_i\)`
+ For any given `\(x_i\)` value, the probability of success is constant. 

]

.pull-right[
&lt;img src="./images/fig7-3.png" width="60%" style="display: block; margin: auto;" /&gt;
]
---

&lt;!-- ## Recap: --&gt;

&lt;!-- Simple linear regression model (not recommended): `$$\pi_i = \beta_0 + \beta_1x_i$$` --&gt;

&lt;!-- Logistic regression model: --&gt;
&lt;!-- `$$ln\left(\frac{\pi_i}{1 - \pi_i}\right) = \beta_0 + \beta_1x_i \implies \pi_i= \frac{e^{\beta_0 + \beta_1x_i}}{1 + e^{\beta_0 + \beta_1x_i}}$$` --&gt;

&lt;!-- ## Recap: --&gt;

&lt;!-- Simple linear regression model with binary response: `$$y_i = \pi_i + \epsilon_i = \beta_0 + \beta_1x_i + \epsilon_i$$` --&gt;

&lt;!-- Logistic regression model with binary response: --&gt;
&lt;!-- `$$y_i = \pi_i + \epsilon_i = \frac{e^{\beta_0 + \beta_1x_i}}{1 + e^{\beta_0 + \beta_1x_i}} + \epsilon_i$$` --&gt;

# Maximum Likelihood Estimation

Recall: we're interested in the relationship between temperature `\(X\)` and O-ring failure `\(Y\)`. 

`$$Y_i = \pi_i + \epsilon_i = \frac{e^{\beta_0 + \beta_1x_i}}{1 + e^{\beta_0 + \beta_1x_i}} + \epsilon_i$$`

What parameters do we need to estimate? 

--

Even though the logistic regression model gets us the S-shaped curve (restricted to 0-1) that we want, the error terms are not constant or normally distributed, which were key assumptions in deriving confidence intervals and hypothesis tests procedures for OLS estimators of `\(\beta_0\)` or `\(\beta_1\)`

--

Maximum Likelihood Estimation (MLE) is another way of deriving estimates for parameters (e.g. `\(\beta_0\)` and `\(\beta_1\)`). In this class, we won't focus on the derivations but will just have software do the MLE for us. 

--


``` r
glm(success ~ temperature, #model formula, just like lm()
    family = "binomial", #distribution &amp; link function specification - see ?family for options
    data = shuttle)
```

### AE #6-7

---

# Interpreting Logistic Regression Models

Interpretation often done in terms of odds of success.

When the temperature is 59&amp;deg;F, the odds of a successful launch with no O-ring damage are `$$\frac{\hat{\pi}}{(1 - \hat{\pi})} = \frac{0.2066}{1-.2066} = 0.2605 \approx 0.25 = \frac{1}{4}$$`

Thus, at 59&amp;deg;F we say the odds of a successful launch are about 1 to 4. 

---

# Slope interpretation

`$$odds = \frac{\pi_i}{(1 - \pi_i)} = e^{\beta_0 + \beta_1x_i} = e^{\beta_0}(e^{\beta_1})^{x_i}$$`
--

Thus, as `\(x_i\)` increases by 1, `$$e^{\beta_0}(e^{\beta_1})^{x_i + 1}=e^{\beta_0}(e^{\beta_1})^{x_i}(e^{\beta_1})$$`

So, increasing `\(x_i\)` by 1 unit in a logistic regression model, increases the predicted odds by a factor of `\(e^{\beta_1}\)`. 

In shuttle example, if temperature increases by 1 degree, we increase the odds of a successful launch by a factor of `$$e^{b_1} = e^{0.232} = 1.2613$$`

---

# Recap: 

Logistic regression models probability of success for a binary response variable

`$$ln\left(\frac{\pi_i}{1 - \pi_i}\right) = \beta_0 + \beta_1x_i$$`

`$$\pi_i= \frac{e^{\beta_0 + \beta_1x_i}}{1 + e^{\beta_0 + \beta_1x_i}}$$`

## What extensions can you imagine?

---

# Generalized Linear Models (GLMs)

Logistic regression is a special case of a **Generalized Linear Model**, which expands linear regression to cases where normal assumptions do not hold. 

--

All GLMs have three components:

1. A **linear predictor**, e.g. `\(\beta_0 + \beta_1x_i\)`. Can have many explanatory variables, including interaction terms

--

2. A **random component** where each error is assumed to be independent. GLMs do NOT assume they are normally distributed, and do NOT require the variability of the errors to be constant.

--

3. A **link function** that fits the expected response value to a linear predictor. E.g. the link function for logistic regression is `\(ln(\pi/(1-\pi))\)`

--

The link function depends on the distribution of the response variable. In logistic regression, the response variable is binary, so a Bernoulli distribution is assumed. 

Other options: gamma, Poisson, etc. 

For linear regression with a normally distributed response, the link function is simply the identity function. I.e., no transformation is needed for OLS. 

---

# More practice

AE-07 #8 - 13

&lt;!-- ## Wald's test --&gt;

&lt;!-- Wald's test for logistic regression coefficients is similar to a one-sample Z-test --&gt;

&lt;!-- `$$H_0: \beta_1 = 0 \text{ vs. } H_A:\beta_1 \neq 0$$` --&gt;

&lt;!-- `$$Z = \frac{b_1 - 0}{se(b_1)}$$` --&gt;

&lt;!-- where `\(b_1\)` is the MLE of `\(\beta_1\)` and `\(se(b_1)\)` is its standard error. `\(b_1\)` is asymptotically normal, so `\(Z \sim N(0,1)\)` when sample size is large. Some textbooks and software will instead use `\(Z^2 \sim \chi^2_{1}\)`, but the tests are equivalent.  --&gt;

&lt;!-- Compute `\(Z\)` for this data, and draw a conclusion. --&gt;

&lt;!-- --- --&gt;

&lt;!-- ## CI for odds ratio --&gt;

&lt;!-- `$$\left(e^{(b_1 - Z^*se(b_1))}, e^{(b_1 + Z^*se(b_1))}\right)$$` --&gt;

&lt;!-- When `\(\beta_1 = 0\)`, then the odds ratio `\(e^{\beta_1} = 1,\)` the odds of success for temperature `\(x_i\)` are the same as the odds of success for any other temperature.  --&gt;

&lt;!-- Compute the confidence interval for this data, and interpret it. --&gt;

&lt;!-- -- --&gt;

&lt;!-- When a 95% CI for the odds ratio does not contain 1, we... --&gt;

&lt;!-- -- --&gt;

&lt;!-- ### AE #12 - 13 --&gt;

&lt;!-- --- --&gt;

&lt;!-- # The Likelihood Ratio Test --&gt;

&lt;!-- The **likelihood ratio test (LRT)** assesses the adequacy of a full model (of interest) and restricted log-likelihood models.  --&gt;

&lt;!-- -- --&gt;

&lt;!-- + The **full model** (or unrestricted model) contains all parameters under consideration in the model (e.g. in this case, `\(\beta_0\)` and `\(\beta_1\)`)  --&gt;

&lt;!-- -- --&gt;

&lt;!-- + The **restricted model** (or reduced model) is a model with fewer terms than the full model  --&gt;

&lt;!-- -- --&gt;

&lt;!-- + If the restricted model contains no explanatory variables, this is called the **null model** --&gt;

&lt;!-- -- --&gt;

&lt;!-- + If the full model has a significantly better fit (the expected values are closer to the observed values) than the restricted model, we reject `\(H_0: \beta_1 = 0\)` and conclude that `\(H_A: \beta_1 \neq 0\)` --&gt;

&lt;!-- --- --&gt;

&lt;!-- # The Likelihood Ratio Test --&gt;

&lt;!-- Restricted model: `$$\pi_i = \frac{e^{\beta_0}}{1 + e^{\beta_0}}$$` --&gt;

&lt;!-- Full model: `$$\pi_i = \frac{e^{\beta_0 + \beta_1x_i}}{1 + e^{\beta_0 + \beta_1x_i}}$$` --&gt;

&lt;!-- When `\(H_0\)` is true, can be shown that  --&gt;

&lt;!-- `$$G = 2\times \text{log-likelihood(full model)} - 2\times \text{log-likelihood(restricted model)}$$` --&gt;
&lt;!-- follows a `\(\chi^2_{df}\)` distribution, where degrees of freedom are the number of parameters in the full model minus the number of parameters in the restricted model.  --&gt;

&lt;!-- The G-statistic measures the difference between the fits of the restricted and full models.  --&gt;

&lt;!-- --- --&gt;

&lt;!-- # LRT in R --&gt;

&lt;!-- R output gives the **null deviance** = `\(K - 2\times \text{log-likelihood(restricted model)}\)` and **residual deviance** = `\(K - 2\times \text{log-likelihood(full model)}\)`, where `\(K\)` is a constant, so G-statistic can be calculated as null deviance - residual deviance.  --&gt;

&lt;!-- ```{r, echo = FALSE} --&gt;
&lt;!-- m2 &lt;- glm(success ~ temperature,  --&gt;
&lt;!--     family = "binomial",  --&gt;
&lt;!--     data = shuttle) --&gt;
&lt;!-- ``` --&gt;


&lt;!-- ```{r} --&gt;
&lt;!-- summary(m2) --&gt;
&lt;!-- ``` --&gt;

&lt;!-- --- --&gt;

&lt;!-- # Wald vs LRT --&gt;

&lt;!-- + LRT is preferable to Wald in small sample sizes --&gt;
&lt;!-- + In general, recommend about n = 100. Make sure to state p-values are approximate if dealing with small sample sizes --&gt;
&lt;!-- + Wald can have one-sided alternative as well as non-zero hypothesized values --&gt;

&lt;!-- --- --&gt;

&lt;!-- # What can we conclude? --&gt;

&lt;!-- ## AE #14 --&gt;
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"slideNumberFormat": "",
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false,
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>
<style>
.logo {
  background-image: url(MATH_062_sticker.png);
  background-size: contain;
  background-repeat: no-repeat;
  position: absolute;
  top: 0.5em;
  right: 0.5em;
  width: 150px;
  height: 100px;
  z-index: 0;
}
</style>

<script>
document
  .querySelectorAll(
    '.remark-slide-content' +
    ':not(.title-slide)' +
    // add additional classes to exclude here, e.g.
    // ':not(.inverse)' +
    ':not(.hide-logo)'
  )
  .forEach(el => {
    el.innerHTML += '<div class="logo"></div>';
  });
</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
