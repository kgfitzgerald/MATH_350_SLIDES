---
title: "AE-CH2"
author: "SOLUTIONS"
format: 
  html:
    self-contained: true
    toc: true
    toc_float: true
    number_section: false
    highlight: "tango"
    theme: "cosmo"
    df-print: paged
editor: visual
editor_options: 
  chunk_output_type: console
---

This Application Exercise walks through the guided activities in Chapter 2 of the textbook. There are spaces for you to answer each question (with code and/or text). Feel free to also use this document to add your own notes along the way.

```{r}
#| label: load-packages
#| message: false
#| warning: false

library(tidyverse)
library(janitor)
library(ggridges)
library(infer)
library(broom)
```

```{r}
#| label: load-data
#| message: false
#| warning: false

games1 <- read_csv("./data/C2 Games1.csv") %>% 
  clean_names()
```

### Question 1

> Units: the students
>
> Population: set of all students at this college who would be willing to be part of the study
>
> Explanatory variable: type of game (standard or w/ color distractor)
>
> Response variable: completion time (in seconds)

### Question 2

> Experiment, since students were randomly assigned to the two game types

### Question 3

> *H*<sub>0</sub> : *μ*<sub>1</sub> = *μ*<sub>2</sub>
>
> > *H*<sub>*A*</sub> : *μ*<sub>1</sub> ≠ *μ*<sub>2</sub>

### Question 4

```{r boxplot}
ggplot(games1, aes(y = time, x = type)) +
  geom_boxplot()
```

> It looks like the means differ but the variances are similar. No unusual observations.

```{r summary-stats}
games1 %>% 
  group_by(type) %>% 
  summarize(ybar = mean(time),
            s = sd(time))
```

\[Skip Q5 & Q6\]

### Question 7

```{r}
#compute residuals
games1 <- games1 %>% 
  group_by(type) %>% 
  mutate(ybar = mean(time),
         residual = time - ybar)

#histogram of residuals
ggplot(games1, aes(x = residual)) +
  geom_histogram(color = "white",
                 binwidth = 2)
  
```

> The residuals look approximately normal.

### Question 8

```{r}
#informal test of equal variance

#create data for group 1
data1 <- games1 %>% filter(type == "Color")
#compute s1
s1 <- sd(data1$time)

#create data for group 2
data2 <- games1 %>% filter(type == "Standard")
#compute s2
s2 <- sd(data2$time)
#informal test
max(s1,s2)/min(s1, s2)
```

> The ratio of the standard deviations is less than 2, so it passes the informal test. The equal variance assumption seems appropriate.

### Question 9

```{r}
ggplot(games1, aes(x = student_id, 
                   y = residual)) +
  geom_point()
```

> There does not appear to be a pattern, so the independence assumption doesn't appear to be violated.

### Question 10

```{r}
#| warning: false
#two-sample t-test for difference in average times by game type
results_Q10 <- t_test(games1, response = time, 
       explanatory = type)
results_Q10
```

> The p-value is `r round(as.numeric(results_Q10[1,3]), 4)`, which is less than *α* = 0.05, so there is sufficient evidence to reject *H*<sub>0</sub>. That is, we can conclude that the color distractor did cause a difference in average game completion time, and the observed difference in means (`r round(as.numeric(results_Q10[1,5]), 3)`) was not just due to chance. We are 95% confident that the true difference in average completion between the two groups is between `r round(as.numeric(results_Q10[1,6]), 3)` and `r round(as.numeric(results_Q10[1,7]), 3)`.

### Question 11

```{r}
#recode so Standard is the reference category
games1 <- games1 %>% 
  mutate(type_recoded = factor(type, 
                       levels = c("Standard",
                                  "Color")))
#fit linear regression model
m1 <- lm(time ~ type_recoded, data = games1)
tidy(m1)
```

### Question 12

The output above has the relevant t-statistic (`r round(as.numeric(tidy(m1)[2,4]), 2)`) and corresponding p-value (`r round(as.numeric(tidy(m1)[2,5]), 4)`) for the test of *H*<sub>0</sub> : *β*<sub>1</sub> = 0.

The code below computes the confidence intervals for *β*<sub>0</sub> and *β*<sub>1</sub>.

```{r}
confint(m1)
```

> We are 95% confident that the true slope (i.e. difference in group means) is between `r round(confint(m1)[2,1], 3)` and `r round(confint(m1)[2,2], 3)`.

### Question 13

```{r}
m2 <- lm(time ~ type, data = games1)
tidy(m2)
confint(m2)
```

> Re-coding the two-level variable to have the opposite level be the reference category simply flips the order of subtraction for *μ*<sub>1</sub> − *μ*<sub>2</sub>, so it just changes the sign of the estimate & test statistic. The p-value (and conclusion) do not change.

### Question 14

```{r}
#create augmented dataset with residuals
m1_aug <- augment(m1)
#add student id variable back in
m1_aug$student_id <- games1$student_id

ggplot(m1_aug, aes(x = .resid)) +
  geom_histogram(binwidth = 2, color = "white")

ggplot(m1_aug, aes(x = student_id, y = .resid)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE)
```

> The residuals seem normally distributed, and independence does not appear to be violated (no significant pattern when ploted against order). Can check correlation if you're unconvinced / concerned by the negative slope.

```{r}
cor(m1_aug$.resid, m1_aug$student_id)
```

### Question 15

```{r}
games1 <- games1 %>% 
  mutate(type_01 = if_else(type == "Color", 1, 0))

ggplot(games1, aes(y = time, x = type_01)) +
  geom_smooth(method = "lm", se = FALSE) +
  geom_point()
tidy(m1)
```

> The intercept (mean for type = 0, the standard group) is `r round(as.numeric(tidy(m1)[1,2]), 1)`. The positive slope of `r round(as.numeric(tidy(m1)[2,2]), 2)` indicates that color distractor increased completion time by `r round(as.numeric(tidy(m1)[2,2]), 1)` seconds, on average. The blue regression line is connecting the dots between the two group means in this case.

### Question 16

> Recall that *μ*<sub>1</sub> = *μ* + *α*<sub>1</sub>, so *α*<sub>1</sub> = *μ*<sub>1</sub> − *μ*. Similarly, *α*<sub>2</sub> = *μ*<sub>2</sub> − *μ*. Therefore, subtracting *α*<sub>1</sub> − *α*<sub>2</sub> gives *μ*<sub>1</sub> − *μ* − (*μ*<sub>2</sub>−*μ*) = *μ*<sub>1</sub> − *μ*<sub>2</sub>. Therefore, a test about *α*<sub>1</sub> − *α*<sub>2</sub> is equivalent to a test about *μ*<sub>1</sub> − *μ*<sub>2</sub>.

### Question 17

> *y*<sub>1, 3</sub> = *μ* + *α*<sub>1</sub> + *ϵ*<sub>1, 3</sub>
> *y*<sub>2, 20</sub> = *μ* + *α*<sub>2</sub> + *ϵ*<sub>2, 20</sub>

### Question 18

> *μ* represents the overall grand mean of both groups, so there is no need to differentiate between groups

### Question 19

```{r}
#compute grand mean
grand_mean <- mean(games1$time)

#compute mean for group 1 (color)
ybar1dot <- mean(data1$time)

#compute mean for group 2 (standard)
ybar2dot <- mean(data2$time)
```

### Question 20

```{r}
#effect size color 
ybar1dot - grand_mean

#effect size standard
ybar2dot - grand_mean
```

### COMPARE RESIDUALS

```{r}
#compute residuals for regression model
#store as new variable res_reg in games1 dataset
# do same for ANOVA residuals, call res_aov
b0 <- as.numeric(tidy(m1)[1,2])
b1 <- as.numeric(tidy(m1)[2,2])

games1 <- games1 %>% 
  mutate(yhat = b0 + b1*type_01,
         res_reg = time - yhat,
         res_aov = time - ybar)

cor(games1$res_reg, games1$res_aov)
```

### Question 23

```{r}
aov_m1 <- anova(m1)
tidy(aov_m1)
```

> The p-value for this F-test is `r round(as.numeric(tidy(aov_m1)[1,6]), 4)`. Therefore, we reject the null hypothesis that the two group effects are equal. That is, there is sufficient evidence to claim that the two groups have different average completion times.

### Question 24

> The p-values are identical.

### Question 25

> `r sqrt(as.numeric(tidy(aov_m1)[1,5]))`. This is the same as the t-value in the regression test for *H*<sub>0</sub> : *β*<sub>1</sub> = 0.

### Question 26

```{r}
ggplot(games1, aes(x = res_aov)) +
  geom_histogram(color = "white",
                 binwidth = 2)

ggplot(games1, aes(y = res_aov, x = student_id)) +
  geom_smooth(method = "lm", se = FALSE) +
  geom_point()

#check if residual variances are similar for both groups
ggplot(games1, aes(x = res_aov)) +
  facet_wrap(~ type) +
  geom_histogram(color = "white",
                 binwidth = 2)

games1 %>% 
  group_by(type) %>% 
  summarize(s = sd(res_aov))
```

> All diagnostic checks indicate assumptions are appropriate.

### Question 27

> When a regression model has one categorical variable with two-levels, and an equal variance assumption is warranted, the regression test for *H*<sub>0</sub> : *β*<sub>1</sub> = 0 is the same as the two-sample t-test (yields the same t-statistic & p-value), and also yields the same p-value as the F-test for an ANOVA model with the same response/explanatory variable. The ANOVA F-statistic is the square of the t-statistics in the other two scenarios. All three models have the same mean response (just use different notation to describe it), and therefore identical residuals. They all make the same assumptions about the distribution of the random errors, too.
